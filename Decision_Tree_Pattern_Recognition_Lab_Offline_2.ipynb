{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree - Pattern Recognition Lab-Offline 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNg/x6fUIFGpNr2ASaR8Bpi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarekHasan011/Pattern-Recognition/blob/main/Decision_Tree_Pattern_Recognition_Lab_Offline_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDYFTm1bLyXe"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "data = pd.read_csv('tic-tac-toe.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Qf62NbOdVN"
      },
      "source": [
        "#Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for column in data.columns:\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "data = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdQTa1DLMbmt"
      },
      "source": [
        "#split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KL5dpTqPJ8N"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, attribute=None, attribute_values=None, child_nodes=None, decision=None):\n",
        "        self.attribute = attribute\n",
        "        self.attribute_values = attribute_values\n",
        "        self.child_nodes = child_nodes\n",
        "        self.decision = decision\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "\n",
        "    root = None\n",
        "\n",
        "    @staticmethod\n",
        "    def plurality_values(data):\n",
        "        labels = data[:, data.shape[1] - 1]  # store the last column in labels\n",
        "        return max(list(labels), key=list(labels).count)\n",
        "\n",
        "    @staticmethod\n",
        "    def all_zero(data):\n",
        "        labels = data[:, data.shape[1] - 1]  # store the last column in labels\n",
        "        return len(set(labels)) == 1 and list(set(labels))[0] == 0\n",
        "\n",
        "    @staticmethod\n",
        "    def all_one(data):\n",
        "        labels = data[:, data.shape[1] - 1]  # store the last column in labels\n",
        "        return len(set(labels)) == 1 and list(set(labels))[0] == 1\n",
        "\n",
        "    @staticmethod\n",
        "    def importance(data, attributes):\n",
        "        labels = data[:, data.shape[1] - 1]  # store the last column in labels\n",
        "        Entropy_S = 0\n",
        "        for i in range(np.max(labels)+1):\n",
        "            Entropy_S += (-(list(labels).count(i)/len(labels)) * np.log2(list(labels).count(i)/len(labels)))\n",
        "        \n",
        "        IG = 0\n",
        "        important_feature = 0\n",
        "\n",
        "        for i in range(data.shape[1]-1):\n",
        "            if i not in attributes:\n",
        "                continue\n",
        "            one_feature = data[:, i]\n",
        "            temp_dictionary = {}\n",
        "            number_of_data_for_each = [0]*(np.max(one_feature)+1)\n",
        "\n",
        "            for j in range(len(one_feature)):\n",
        "                if (one_feature[j],labels[j]) not in temp_dictionary:\n",
        "                    temp_dictionary[(one_feature[j],labels[j])] = 1\n",
        "                else:\n",
        "                    temp_dictionary[(one_feature[j],labels[j])] += 1\n",
        "                number_of_data_for_each[one_feature[j]] += 1\n",
        "\n",
        "            temp_Information_Gain = Entropy_S\n",
        "            for j in range(len(number_of_data_for_each)):\n",
        "                temp_entropy = 0\n",
        "                for k in range(np.max(labels)+1):\n",
        "                    if (j,k) not in temp_dictionary:\n",
        "                        continue\n",
        "                    temp_entropy += (-(temp_dictionary[(j,k)]/number_of_data_for_each[j]) * np.log2(temp_dictionary[(j,k)]/number_of_data_for_each[j]))\n",
        "                temp_Information_Gain -= (temp_entropy)*(number_of_data_for_each[j]/len(one_feature))\n",
        "            if temp_Information_Gain > IG:\n",
        "                IG = temp_Information_Gain\n",
        "                important_feature = i\n",
        "        return important_feature\n",
        "                    \n",
        "\n",
        "    def train(self, data, attributes, parent_data):\n",
        "        data = np.array(data)\n",
        "        parent_data = np.array(parent_data)\n",
        "        attributes = list(attributes)\n",
        "\n",
        "        if data.shape[0] == 0:  # if x is empty\n",
        "            return Node(decision=self.plurality_values(parent_data))\n",
        "\n",
        "        elif self.all_zero(data):\n",
        "            return Node(decision=0)\n",
        "\n",
        "        elif self.all_one(data):\n",
        "            return Node(decision=1)\n",
        "\n",
        "        elif len(attributes) == 0:\n",
        "            return Node(decision=self.plurality_values(data))\n",
        "\n",
        "        else:\n",
        "            a = self.importance(data, attributes)\n",
        "            tree = Node(attribute=a, attribute_values=np.unique(data[:, a]), child_nodes=[])\n",
        "            attributes.remove(a)\n",
        "            for vk in np.unique(data[:, a]):\n",
        "                new_data = data[data[:, a] == vk, :]\n",
        "                subtree = self.train(new_data, attributes, data)\n",
        "                tree.child_nodes.append(subtree)\n",
        "\n",
        "            return tree\n",
        "\n",
        "    def fit(self, data):\n",
        "        self.root = self.train(data, list(range(data.shape[1] - 1)), np.array([]))\n",
        "\n",
        "    def predict(self, data):\n",
        "        predictions = []\n",
        "        for i in range(data.shape[0]):\n",
        "            current_node = self.root\n",
        "            while True:\n",
        "                if current_node.decision is None:\n",
        "                    current_attribute = current_node.attribute\n",
        "                    current_attribute_value = data[i, current_attribute]\n",
        "                    if current_attribute_value not in current_node.attribute_values:\n",
        "                        predictions.append(random.randint(0, 1))\n",
        "                        break\n",
        "                    idx = list(current_node.attribute_values).index(current_attribute_value)\n",
        "\n",
        "                    current_node = current_node.child_nodes[idx]\n",
        "                else:\n",
        "                    predictions.append(current_node.decision)\n",
        "                    break\n",
        "\n",
        "        return predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee7LMrRrVtTg"
      },
      "source": [
        "DT = DecisionTree()\n",
        "DT.fit(train_data)\n",
        "prediction = DT.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j6p5a5OcJpo",
        "outputId": "dd9b255c-c0d9-4ff5-90e6-d6387bdaab26"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(prediction,test_data[:,test_data.shape[1]-1])\n",
        "precision = precision_score(prediction,test_data[:,test_data.shape[1]-1])\n",
        "recall = recall_score(prediction,test_data[:,test_data.shape[1]-1])\n",
        "f1 = f1_score(prediction,test_data[:,test_data.shape[1]-1])\n",
        "print(f'{accuracy} {precision} {recall} {f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.890625 0.925 0.9024390243902439 0.9135802469135802\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}